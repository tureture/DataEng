{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88182d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/02/23 17:07:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Assignment 3 Data Engineering 5hp\n",
    "# Part B\n",
    "# By Ture Hassler\n",
    "\n",
    "# Initialize spark session and spark context\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "ss = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"spark://192.168.2.122:7077\") \\\n",
    "    .appName(\"turehassler_partA\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "    .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "    .config(\"spark.cores.max\", 16)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = ss.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6311800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+---------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|       Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|Agency Description|Color Description|Body Style Description|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+---------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|   1103341116|2015-12-21 00:00:00|    1251.0|    null|       null|            CA|         200304.0|null|HOND|        PA|   GY|13147 WELBY WAY|01521|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              null|             null|                  null|\n",
      "|   1103700150|2015-12-21 00:00:00|    1435.0|    null|       null|            CA|         201512.0|null| GMC|        VN|   WH|  525 S MAIN ST| 1C51|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0|  99999.0|  99999.0|              null|             null|                  null|\n",
      "|   1104803000|2015-12-21 00:00:00|    2055.0|    null|       null|            CA|         201503.0|null|NISS|        PA|   BK|  200 WORLD WAY|  2R2|   2.0|          8939|           WHITE CURB|       58.0|6439997.9|1802686.4|              null|             null|                  null|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+---------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrame and show that it works\n",
    "df = ss.read.csv(\"hdfs://host-192-168-2-122:9000/parking-citations.csv\", sep=',', inferSchema=True, header=True)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d044c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:  StructType(List(StructField(Ticket number,StringType,true),StructField(Issue Date,TimestampType,true),StructField(Issue time,DoubleType,true),StructField(Meter Id,StringType,true),StructField(Marked Time,DoubleType,true),StructField(RP State Plate,StringType,true),StructField(Plate Expiry Date,DoubleType,true),StructField(VIN,StringType,true),StructField(Make,StringType,true),StructField(Body Style,StringType,true),StructField(Color,StringType,true),StructField(Location,StringType,true),StructField(Route,StringType,true),StructField(Agency,DoubleType,true),StructField(Violation code,StringType,true),StructField(Violation Description,StringType,true),StructField(Fine amount,DoubleType,true),StructField(Latitude,DoubleType,true),StructField(Longitude,DoubleType,true),StructField(Agency Description,StringType,true),StructField(Color Description,StringType,true),StructField(Body Style Description,StringType,true)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=============================>                            (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr rows:  13077724\n",
      "Nr partitions:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Schema: \", df.schema)\n",
    "print(\"Nr rows: \", df.count())\n",
    "print(\"Nr partitions: \", df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1b9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "d2 = df.drop(\"VIN\", \"Latitude\", \"Longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03314c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=================================================>       (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(Fine amount)|\n",
      "+----------------+\n",
      "|          1100.0|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "d3 = d2.withColumn(\"Fine amount\", d2[\"Fine amount\"].cast(DoubleType()))\n",
    "\n",
    "from pyspark.sql.functions import max\n",
    "d3.select(max(d3[\"Fine amount\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c179f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|2150768|\n",
      "|HOND|1479996|\n",
      "|FORD|1116235|\n",
      "|NISS| 945133|\n",
      "|CHEV| 892676|\n",
      "| BMW| 603092|\n",
      "|MERZ| 543298|\n",
      "|VOLK| 432030|\n",
      "|HYUN| 404917|\n",
      "|DODG| 391686|\n",
      "|LEXS| 368420|\n",
      "| KIA| 328155|\n",
      "|JEEP| 316300|\n",
      "|AUDI| 255395|\n",
      "|MAZD| 242344|\n",
      "|OTHR| 205546|\n",
      "| GMC| 184889|\n",
      "|INFI| 174315|\n",
      "|CHRY| 159948|\n",
      "|SUBA| 154640|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Groups by car brand, counts and displays descending order first 20 rows\n",
    "d3.groupBy('Make').count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d12b1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "COLORS = {\n",
    "'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black', 'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze', 'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold', 'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory', 'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon', 'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver', 'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White', 'WH':'White', 'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown'\n",
    "}\n",
    "\n",
    "# Actual function\n",
    "def colorLong(s):\n",
    "    if s in COLORS:\n",
    "        return COLORS[s]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# User defined function boilerplate code\n",
    "udf_colorLong = udf(lambda x: colorLong(x))\n",
    "\n",
    "# Use withColumn to create a new column with long color names\n",
    "d4 = d3.withColumn(\"color long\", udf_colorLong(col(\"color\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaed3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|color long| count|\n",
      "+----------+------+\n",
      "|      Gray|489697|\n",
      "|     White|434595|\n",
      "|     Black|353812|\n",
      "|    Silver|347894|\n",
      "|      Blue|180091|\n",
      "|       Red|119074|\n",
      "|     Green| 74968|\n",
      "|      Gold| 40646|\n",
      "|    Maroon| 26242|\n",
      "|       Tan| 23355|\n",
      "|     Beige| 15723|\n",
      "|        OT| 15719|\n",
      "|     Brown| 11454|\n",
      "|    Yellow|  4372|\n",
      "|        PR|  4272|\n",
      "|    Orange|  3575|\n",
      "|   Unknown|  2012|\n",
      "|        TU|  1647|\n",
      "|      null|   771|\n",
      "|        CO|   730|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filter to get only Toyotoa cars\n",
    "toyota_df = d4.filter(col(\"make\") == \"TOYT\")\n",
    "\n",
    "# Group the dataframe by color and count the number of occurrences of each color\n",
    "color_counts = toyota_df.groupBy(\"color long\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Seems to rougly line up with the total amount of toyota cars so should be correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab148f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
